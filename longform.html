<!DOCTYPE HTML>
<html>
	<head>
		<title>Longform Piece</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body>
		<div id="wrapper">
			<nav>
				<a href="index.html#essays">Theorist Panel</a> |
				<a href="index.html#prose">Accessibility Report</a> |
				<a href="index.html#about">About</a> |
				<a href="index.html#contact">Contact</a>
			</nav>
		<header>
			<h1>Longform Piece</h1>
		</header>
			<p class="indent">Recently, I conducted a usability test for the community feature from the music sharing website RateYourMusic. Created in 2000, RateYourMusic has become one of the internet’s most prominent platforms for discovering new music and fostering a sense of community among its users. The usability test was completed in several stages beginning with a heuristic evaluation of the feature which was then used to create a test plan. After getting feedback on and revising the test plan, I staked out the necessary dialogue and tools to conduct the usability test in the test materials stage. Then, after conducting the usability test, I completed the project by creating a test report to articulate my findings.</p>  
 
<h3>Heuristic Evaluation</h3> 
<p class="indent">For the heuristic evaluation, I designated myself as the expert user given my prior experience with RateYourMusic as a website and my knowledge of music-sharing websites more generally. The heuristic evaluation was broken down into several distinct sections: Introduction, Purpose, Methodology, Findings, High, Medium, and Low Priority Concerns, and a Conclusion.</p>
 
<p class="indent">The introduction section gave a bit of background information about RateYourMusic, particularly emphasizing key features like its five-star rating system and filtering methods. The purpose section established the central goal of the heuristic evaluation: to pinpoint navigational flaws within the community feature through a single user’s observations.</p>
 
<p class="indent">The methodology section outlined the steps I took during the heuristic evaluation that led me to my overall findings starting first with observations about the stylistic features of the community homepage, then taking note of formatting and overall display.</p>
 
 <p class="indent">In the findings section, I structured my feedback into five focus areas labeled from A to E: Homepage Global Map, Color Scheme & Spacing, Headings On Homepage, Miscellaneous User Posts at the Bottom of the Page, and Search Feature Confusion. Each of these subsections identified at least one but usually several concerns each with a corresponding suggestion and numerical value from 1-4 to indicate each concern’s severity.</p>
 
<p class="indent">With the previously mentioned severity ratings in mind, the Concerns sections ranked the concerns by priority, from high to low. Although I did not give any of the concerns a 4 on the severity scale, several concerns received a 3 These included the random recent posts found at the bottom of the community tab homepage, the search engine filtering results by key headings rather than keywords, and the generally disorganized subheadings at the bottom of the community homepage. All these concerns were put in the high-priority section because they appeared to be the most substantial and would likely take the most effort to address from a design perspective.</p>
 
<p class="indent">Concerns like inconsistent capitalization, the unclear distinction between the ‘Posts’ and ‘All’ categories, and the website’s non-section 508 compliant color scheme, were all categorized as medium-priority. While these concerns were easier to address, doing so would likely improve the quality of the community feature significantly.</p>
 
<p class="indent">Low-priority concerns were mostly stylistic, including the debatable inclusion of the global map on the community homepage and the unnecessary empty space at the top of the page. These concerns were easy to fix and were the least important for designers to address in the long run given the other concerns.</p>
 
<p class="indent">In the conclusion section, I established the usability test categories I would use throughout the remainder of the project, based primarily on the structure of the findings section. These categories included: visual appeal, organization, and usability. The goal of using these categories was to focus each user’s feedback on certain general areas without forcing said feedback to take any specific direction.</p> 
 
<h3>Test Plan</h3> 
	<p class="indent">The goal of the test plan was to hone in on the characteristics of the usability test users, outline the tasks they would be completing, and specify any risks users may be taking by participating in the usability test. Consequently, the test plan was divided into the following sections: Participants, Scenarios, Tasks, and Risk Mitigation.</p>
	
	<p class="indent">In the participants section, I identify the demographics and background of the users. Out of the five total users, three fell within the age range of 19-21 while the other two fell within the age range of 35-58. None of the five participants had any prior experience with RateYourMusic but all of the participants were well-acquainted with blog-style websites and the internet more broadly.</p>
 
<p class="indent">To give a better sense of the specific characteristics of the likely user for my usability test, I created two scenarios, one covering the younger demographic and another covering the older demographic. The first scenario describes James, a 19-year-old college student who has been getting more interested in music but often feels overwhelmed by the wealth of information he is faced with when trying to discover music online.</p>
 
<p class="indent">The second scenario describes June, a 53-year-old technical writer who has listened to music casually but extensively for years given her family listens to a wide variety of it and is now being encouraged by a friend to catalog the music she has listened to over the years just for the fun of it. Key to both of these scenarios is each individual’s need for an accessible resource that does not present any obstacles for someone who is either new to or only casually using a music rating platform.</p>
 
	<p class="indent">The tasks section primarily included the questions users were asked as part of the usability test. Although these questions and instructions were further expanded upon in the final test materials portion of the usability test, many of the questions within each of the three sections (i.e. visual appeal, organization, & usability), as well as the 1-4 scale section rating, carried over into the final test materials. I will talk about these features further in the next section.</p>
 
	<p class="indent">Despite there being few if any major risks in participating in this usability test, I was still able to identify two potential risks and some potential mitigation strategies in the risk mitigation section of the test plan. The first of these is the possibility that the RateYourMusic interface for the community feature may be different depending on the operating system the participant is using. To solve this, I planned to have all participants use the same interface during the usability test.</p> 
 
<p class="indent">The second potential risk was that participants could be disoriented upon entering the website without any initial indication of where to go or what to do. This was addressed by including a detailed set of instructions that told participants exactly what to do and where to go once they navigated to the website.</p> 

<h3>Test Materials</h3> 
	<p class="indent">The test materials section was the exact script I followed when conducting the usability test. It begins with a brief description of the structure and approach of the test including the detailed instructions mentioned in the risk mitigation section of the previously mentioned test plan.</p> 
 
<p class="indent">Participants were then asked some preliminary questions before getting into the individual tasks to gauge each one’s prior experience with rating music and whether they see themselves doing so in the future.</p>
 
<p class="indent">The design appeal section asked participants to find the ‘users online’ feature, followed by the ‘Featured posts’ feature, and then the global map. After completing these tasks, participants were asked to describe what they found to be the most visually appealing features. Participants were then asked how the page’s organization differed from what they generally expect from a community page and whether the heading provided the most relevant information to the user.</p>
 
	<p class="indent">The organization section asked participants to find RateYourMusic’s stance on Wiki Editing. After completing the task, the participants were asked to list three struggles they had in finding this information and one aspect of the way the site was organized that made this process easier. The post-task questions asked whether the pages they navigated used the most relevant headings and whether they were misleading along with the same post-task questions from the design appeal section.</p>
 
	<p class="indent">The usability section asked participants to find a post from a specific user about their favorite classical music composer. Participants were then asked if there was anything difficult or confusing about this search process and their overall experience navigating the search results they found.</p>
 
	<p class="indent">To conclude the usability test, participants were asked to give the RateYourMusic community feature a rating from 1 to 4 for each of the categories covered (i.e. (i.e. visual appeal, organization, & usability) with 1 = Unacceptable; 2 = Needs Improvement; 3 = Satisfactory; 4 = No Changes Should Be Made. The average score for each category is given in the test report section.</p>  
 
<h3>Test Report</h3> 
	<p class="indent">Along with reporting the results of the usability test, the test report recaps all the previous portions of the project much in the same way this piece does. For this reason, I will only cover the results from the test report to avoid any unnecessary repetition.</p>
 
	<p class="indent">The usability test findings were divided up into the following sections: Pre Usability Test, Visual Appeal, Organization, Usability,  Average Section Ratings, and Recommendations.</p>
 
<p class="indent">For the pre usability test, two of the five participants had rated music in some capacity before although this was not something they did on a consistent basis. It followed then that these same two participants expressed interest in using a music rating system sometime in the future while the other three showed no interest.</p>
 
<p class="indent">In the visual appeal section, none of the participants expressed any confusion or difficulty with completing the tasks. Visual appeal quality was more contentious with some favoring the site’s current minimalistic design and others thinking that the website looked amateurish and incomplete with the website’s default dark background being a common complaint from these users. Most of the participants (4 out of 5) liked the global user map as a feature with the one who did not saying that more relevant graphics could have been used instead. Most participants disliked the column layout of the homepage, criticizing its repetitiveness and unnecessary size differences.</p>
 
<p class="indent">In the organization section, 3 of the 5 participants were able to complete the task with little trouble. Both of the participants who did not complete the task found themselves overwhelmed by the number of choices they were faced with once they had navigated to the site policy page. Even the participants who successfully completed the task found the large number of options within the site policy page made for an unnecessarily difficult navigating experience.</p>
 
<p class="indent">In the usability section, most participants struggled to complete the task with only two successfully doing so. The primary issue participants pointed to, similar to the organization section, was the number of results available on the search results landing page with one participant going as far as to describe it as impenetrable. One of the two participants who successfully completed the task cited the search bar’s filtering feature as an effective way to sift through the large number of results they were faced with.</p>
 
<p>The following chart was created to display the average section ratings among the five users-</p>
 
<table>
	<tr>
		<th>Category</th>
	</tr>
	<tr>
		<td>Visual Appeal</td>
		<td>Organization</td>
		<td>Usability</td>
	</tr>
	<tr>
		<th>Average Rating</th>
	</tr>
	<tr>
		<td>3.8</td>
		<td>3.5</td>
		<td>2.8</td>
	</tr>
</table>
     
	<p class="indent">Given the results of the usability test, I then recommended that designers prioritize giving users fewer content options to choose from on any given page given the increasing navigation problems this issue caused for participants as tasks became more complex. My other recommendation was that designers pay greater attention to new users in redesigning considering that several participants complained that the design of the community feature felt aimed toward an already insular community that was not welcoming of new members.</p>

		<footer id="footer">
	<p class="copyright">&copy; Evan Salsieder 2022.</p>
</footer>
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>